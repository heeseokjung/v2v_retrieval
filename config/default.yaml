SEED: 42
PATH:
  LOG_PATH: "log"
  CKPT_PATH: "ckpt"
RELEVANCE:
  type: "dtw"
  mean:
  smooth_chamfer:
    alpha: 16
DATASET:
  moma:
    path: "/data/dir_moma"
    paradigm: "standard"
    tail_range: 400
    use_over_sampling: True
MODEL:
  LOAD_FROM: "ours"
  name: "slot" 
  S3D:
    projector:
      in_dim: 1024
      hidden_dim: 512
      out_dim: 384
      dropout: 0.1
    use_kinetics_pretrained: True
    freeze: True
    clip_duration: 8
    frames_per_clip: 64
    stride: 2
  FROZEN:
    projector:
      in_dim: 768
      hidden_dim: 384
      out_dim: 384
      dropout: 0.1
    num_frames: 4
    time_init: "zeors"
    attention_style: "frozen-in-time"
    emb_type: "set" # "flat" or "set"
    use_cc_web_pretrained: True
    freeze: True
    clip_duration: 8
  TRANSFORMER:
    in_dim: 768
    d_model: 768
    max_len: 700
    nhead: 8
    dim_feedforward: 1024
    dropout: 0.1
    num_layers: 2
  SLOT: 
    slot:
      num_slots: 8
      dim: 768
      iters: 3
      eps: 1e-8
      hidden_dim: 768
    encoder:
      in_dim: 768
      d_model: 768
      max_len: 700
      nhead: 8
      dim_feedforward: 1024
      dropout: 0.1
      num_layers: 2
TRAIN:
  dataset: "moma"
  optimizer: "adam"
  batch_size: 16
  num_workers: 0
  pin_memory: True
  persistent_workers: False
  num_epochs: 400
  lr: 0.00001
  loss:
    gamma: 0.05
EVAL:
  split: "val"
  dataset: "moma"
  num_workers: 0
  pin_memory: True
  persistent_workers: False
TRAINER:
  logger: "wandb"