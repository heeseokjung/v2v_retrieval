{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/cvpr24_video_retrieval/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from momaapi import MOMA\n",
    "from utils.attr_dict import AttrDict\n",
    "from utils.main_utils import seed_everything\n",
    "from utils.clip_sampler import s3d_clip_sampler\n",
    "from models.s3d import S3D\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/default.yaml\", \"r\") as f:\n",
    "    cfg = yaml.load(f, yaml.FullLoader)\n",
    "    cfg = AttrDict(cfg)\n",
    "\n",
    "if \"SEED\" in cfg:\n",
    "    seed_everything(cfg.SEED)\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = S3D(cfg)\n",
    "\n",
    "path = os.path.join(\n",
    "    cfg.PATH.CKPT_PATH, \"S3D\", \"S3D_kinetics400.pt\"\n",
    ")\n",
    "assert os.path.isfile(path)\n",
    "\n",
    "weight_dict = torch.load(path)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "for name, param in weight_dict.items():\n",
    "    if \"module\" in name:\n",
    "        name = '.'.join(name.split('.')[1:])\n",
    "    if name in model_dict:\n",
    "        assert param.size() == model_dict[name].size()\n",
    "        model_dict[name].copy_(param)\n",
    "\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(snippet):\n",
    "    ''' stack & noralization '''\n",
    "    snippet = np.concatenate(snippet, axis=-1)\n",
    "    snippet = torch.from_numpy(snippet).permute(2, 0, 1).contiguous().float()\n",
    "    snippet = snippet.mul_(2.).sub_(255).div(255)\n",
    "\n",
    "    return snippet.view(1,-1,3,snippet.size(1),snippet.size(2)).permute(0,2,1,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3d_args = cfg.MODEL.VIDEO.S3D\n",
    "raw_path = \"/data/dir_moma/videos/raw\"\n",
    "feat_path = \"/data/dir_moma/feats/s3d\"\n",
    "\n",
    "for filename in tqdm(os.listdir(raw_path)):\n",
    "    vid = filename[:-4] # remove .mp4\n",
    "    clip_duration = s3d_args.clip_duration\n",
    "    frames_per_clip = s3d_args.frames_per_clip\n",
    "    stride = s3d_args.stride\n",
    "\n",
    "    sampled_clips = s3d_clip_sampler(\n",
    "        os.path.join(raw_path, filename), clip_duration, frames_per_clip, stride\n",
    "    )\n",
    "\n",
    "    embeddings = []\n",
    "    for clip in sampled_clips:\n",
    "        # clip: [h x w x 3, ... (x n_frames)]\n",
    "        clip = transform(clip) # 1 x 3 x n_frames x h x w\n",
    "        with torch.no_grad():\n",
    "            emb = model(clip.cuda()) # 1 x 1024\n",
    "        embeddings.append(emb.detach().cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0) # n_clips x 1024\n",
    "    np.save(os.path.join(feat_path, f\"{vid}.npy\"), embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
